_target_: src.models.transformer_module.TransformerModule

net: 
  _target_: src.models.components.TransformerTorch
  num_encoder_layers: 3
  num_decoder_layers: 3
  emb_size: 192
  nhead: 6
  src_vocab_size: 34687 # len(en_vocab)
  tgt_vocab_size: 21681 # len(vi_vocab)
  dim_feedforward: 192
  dropout: 0.1

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.0001
  betas: [0.9, 0.98]
  eps: 1e-9

scheduler: null